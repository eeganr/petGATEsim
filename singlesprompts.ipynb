{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "60f535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot\n",
    "import pandas as pd\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "# === CONFIG ===\n",
    "input_root_file = \"pastoutput/output2.root\"\n",
    "cont_magnitude = 1e-5\n",
    "num_TOF_bins = 9\n",
    "TOF_bin_width = 29\n",
    "sigma_TOF = 60\n",
    "num_iterations = 2\n",
    "num_subsets = 8\n",
    "\n",
    "total_time = 1 # total sim time (s)\n",
    "TAU = 1.2e-8 # coincidence window (s)\n",
    "\n",
    "image_shape = (200, 200, 700)  # (x, y, z) voxels # originally (310, 310, 310)\n",
    "voxel_size = (0.1, 0.1, 0.1)  #mm #originally (1,1,1)\n",
    "radius_mm = 10 # orinally 130 (mm)\n",
    "use_tof = True # originally False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bdd46977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from ROOT files\n",
    "\n",
    "def get_all_vals(file, name):\n",
    "    num = max([int(i.split(';')[1]) for i in file.keys() if i.split(';')[0] == name])\n",
    "    return file[f'{name};{num}']\n",
    "\n",
    "with uproot.open(input_root_file) as file:\n",
    "    singles_tree = get_all_vals(file, 'Singles')\n",
    "    coincidence_tree = get_all_vals(file, 'Coincidences')\n",
    "\n",
    "    singles = pd.DataFrame({\n",
    "        \"time\": singles_tree[\"time\"].array(library=\"np\"),\n",
    "        \"detector\": singles_tree[\"crystalID\"].array(library=\"np\"),\n",
    "        \"source\": list(map(tuple, np.stack((singles_tree[\"sourcePosX\"].array(library=\"np\"), \n",
    "                            singles_tree[\"sourcePosY\"].array(library=\"np\"), \n",
    "                            singles_tree[\"sourcePosZ\"].array(library=\"np\")), axis=-1))),\n",
    "    })\n",
    "    coincidences = pd.DataFrame({\n",
    "        \"time1\": coincidence_tree[\"time1\"].array(library=\"np\"),\n",
    "        \"time2\": coincidence_tree[\"time2\"].array(library=\"np\"),\n",
    "        \"detector1\": coincidence_tree[\"crystalID1\"].array(library=\"np\"),\n",
    "        \"detector2\": coincidence_tree[\"crystalID2\"].array(library=\"np\"),\n",
    "        \"source1\": list(map(tuple, np.stack((coincidence_tree[\"sourcePosX1\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosY1\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosZ1\"].array(library=\"np\")), axis=-1))),\n",
    "        \"source2\": list(map(tuple, np.stack((coincidence_tree[\"sourcePosX2\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosY2\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosZ2\"].array(library=\"np\")), axis=-1))),\n",
    "    })\n",
    "    coincidences['true'] = coincidences['source1'] == coincidences['source2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3564a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-Wide Equation Constants\n",
    "\n",
    "S = singles_tree.num_entries / total_time # Rate of singles measured by scanner as a whole\n",
    "P = 2 * coincidence_tree.num_entries / total_time # Twice the prompts rate\n",
    "\n",
    "\n",
    "# Roots of this function are the lambda (L) values.\n",
    "def lambda_eq(L):\n",
    "    return 2 * TAU * L * L - L + S - P * np.exp((L + S)*TAU)\n",
    "\n",
    "L = root_scalar(lambda_eq, x0=0)\n",
    "if not L.converged:\n",
    "    raise RuntimeError(\"Failed to converge on lambda.\")\n",
    "L = L.root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "85375cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsrate(i, j):\n",
    "    P_i = len(coincidences[coincidences['detector1'] == i]) + len(coincidences[coincidences['detector2'] == i])\n",
    "    P_j = len(coincidences[coincidences['detector1'] == j]) + len(coincidences[coincidences['detector2'] == j])\n",
    "    S_i = len(singles[singles['detector'] == i])\n",
    "    S_j = len(singles[singles['detector'] == j])\n",
    "    coeff = (2 * TAU * np.exp(-(L + S)*TAU))/((1 - 2 * L * TAU)**2)\n",
    "    i_term = S_i - np.exp((L + S)*TAU) * P_i\n",
    "    j_term = S_j - np.exp((L + S)*TAU) * P_j\n",
    "    return coeff * i_term * j_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d3412fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_24108\\3672908940.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(len(detectors)):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m      6\u001b[39m         print(\u001b[33mf\"Processing detector {i + 1}/{len(detectors)}\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;28;01min\u001b[39;00m range(i, len(detectors)):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         total += randomsrate(detectors[i], detectors[j])\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m print(total)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_24108\\540866377.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(i, j)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m randomsrate(i, j):\n\u001b[32m      2\u001b[39m     P_i = len(coincidences[coincidences[\u001b[33m'detector1'\u001b[39m] == i]) + len(coincidences[coincidences[\u001b[33m'detector2'\u001b[39m] == i])\n\u001b[32m      3\u001b[39m     P_j = len(coincidences[coincidences[\u001b[33m'detector1'\u001b[39m] == j]) + len(coincidences[coincidences[\u001b[33m'detector2'\u001b[39m] == j])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     S_i = len(singles[singles[\u001b[33m'detector'\u001b[39m] == i])\n\u001b[32m      5\u001b[39m     S_j = len(singles[singles[\u001b[33m'detector'\u001b[39m] == j])\n\u001b[32m      6\u001b[39m     coeff = (\u001b[32m2\u001b[39m * TAU * np.exp(-(L + S)*TAU))/((\u001b[32m1\u001b[39m - \u001b[32m2\u001b[39m * L * TAU)**\u001b[32m2\u001b[39m)\n\u001b[32m      7\u001b[39m     i_term = S_i - np.exp((L + S)*TAU) * P_i\n",
      "\u001b[32mc:\\Users\\eegan\\miniconda3\\envs\\pet\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4089\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.where(key)\n\u001b[32m   4090\u001b[39m \n\u001b[32m   4091\u001b[39m         \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m   4092\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m4093\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_bool_array(key)\n\u001b[32m   4094\u001b[39m \n\u001b[32m   4095\u001b[39m         \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[32m   4096\u001b[39m         \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\eegan\\miniconda3\\envs\\pet\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4150\u001b[39m \n\u001b[32m   4151\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key.all():\n\u001b[32m   4152\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   4153\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m4154\u001b[39m         indexer = key.nonzero()[\u001b[32m0\u001b[39m]\n\u001b[32m   4155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._take_with_is_copy(indexer, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "detectors = singles['detector'].unique()\n",
    "print(len(detectors))\n",
    "for i in range(len(detectors)):\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processing detector {i + 1}/{len(detectors)}\")\n",
    "    for j in range(i, len(detectors)):\n",
    "        total += randomsrate(detectors[i], detectors[j])\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f42fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7cacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
