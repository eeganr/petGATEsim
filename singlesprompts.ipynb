{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6606902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%pip3` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas scipy uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "60f535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import root_scalar\n",
    "# import struct\n",
    "import uproot\n",
    "\n",
    "# === CONFIG ===\n",
    "INFILE = \"/scratch/users/eeganr/pastoutput/output1.root\"\n",
    "NUM_VOLIDS = 6\n",
    "cont_magnitude = 1e-5\n",
    "num_TOF_bins = 9\n",
    "TOF_bin_width = 29\n",
    "sigma_TOF = 60\n",
    "num_iterations = 2\n",
    "num_subsets = 8\n",
    "\n",
    "total_time = 60.0 # total sim time (s)\n",
    "TAU = 1.2e-8 # coincidence window (s)\n",
    "DELAY = TAU # delayed window offset (s)\n",
    "num_detectors = 48 * 48\n",
    "\n",
    "image_shape = (200, 200, 700)  # (x, y, z) voxels # originally (310, 310, 310)\n",
    "voxel_size = (0.1, 0.1, 0.1)  #mm #originally (1,1,1)\n",
    "radius_mm = 10 # orinally 130 (mm)\n",
    "use_tof = True # originally False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bdd46977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from ROOT files\n",
    "\n",
    "def get_all_vals(file, name):\n",
    "    num = max([int(i.split(';')[1]) for i in file.keys() if i.split(';')[0] == name])\n",
    "    return file[f'{name};{num}']\n",
    "\n",
    "with uproot.open(INFILE) as file:\n",
    "    singles_tree = get_all_vals(file, 'Singles')\n",
    "    coincidence_tree = get_all_vals(file, 'Coincidences')\n",
    "\n",
    "    singles = pd.DataFrame({\n",
    "        \"time\": singles_tree[\"time\"].array(library=\"np\"),\n",
    "        \"detector\": singles_tree[\"crystalID\"].array(library=\"np\"),\n",
    "        \"source\": list(map(tuple, np.stack((singles_tree[\"sourcePosX\"].array(library=\"np\"), \n",
    "                            singles_tree[\"sourcePosY\"].array(library=\"np\"), \n",
    "                            singles_tree[\"sourcePosZ\"].array(library=\"np\")), axis=-1))),\n",
    "    })\n",
    "    coincidences = pd.DataFrame({\n",
    "        \"time1\": coincidence_tree[\"time1\"].array(library=\"np\"),\n",
    "        \"time2\": coincidence_tree[\"time2\"].array(library=\"np\"),\n",
    "        \"detector1\": coincidence_tree[\"crystalID1\"].array(library=\"np\"),\n",
    "        \"detector2\": coincidence_tree[\"crystalID2\"].array(library=\"np\"),\n",
    "        \"source1\": list(map(tuple, np.stack((coincidence_tree[\"sourcePosX1\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosY1\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosZ1\"].array(library=\"np\")), axis=-1))),\n",
    "        \"source2\": list(map(tuple, np.stack((coincidence_tree[\"sourcePosX2\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosY2\"].array(library=\"np\"), \n",
    "                            coincidence_tree[\"sourcePosZ2\"].array(library=\"np\")), axis=-1))),\n",
    "    })\n",
    "    coincidences['true'] = coincidences['source1'] == coincidences['source2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3564a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-Wide Equation Constants\n",
    "\n",
    "S = len(singles) / total_time # Rate of singles measured by scanner as a whole\n",
    "P = 2 * len(coincidences) / total_time # Twice the prompts rate\n",
    "\n",
    "# Roots of this function are the lambda (L) values.\n",
    "def lambda_eq(L):\n",
    "    return 2 * TAU * L * L - L + S - P * np.exp((L + S)*TAU)\n",
    "\n",
    "L = root_scalar(lambda_eq, x0=0)\n",
    "if not L.converged:\n",
    "    raise RuntimeError(\"Failed to converge on lambda.\")\n",
    "L = L.root\n",
    "\n",
    "det1_counts = coincidences['detector1'].value_counts().to_dict() # det1 coincidences involved\n",
    "det2_counts = coincidences['detector2'].value_counts().to_dict() # det2 coincidences involved\n",
    "\n",
    "prompts = pd.DataFrame({'detector': list(range(num_detectors))})\n",
    "prompts['prompts'] = prompts['detector'].map(lambda x: det1_counts.get(x, 0) + det2_counts.get(x, 0))\n",
    "prompt_count = prompts.set_index('detector')['prompts'].to_dict()\n",
    "singles_counts = singles['detector'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85375cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the randoms rate from a pair of detectors with crystalIDs i and j\n",
    "def randomsrate(i, j):\n",
    "    P_i = prompt_count.get(i, 0) / total_time\n",
    "    P_j = prompt_count.get(j, 0) / total_time\n",
    "    S_i = singles_counts.get(i, 0) / total_time\n",
    "    S_j = singles_counts.get(j, 0) / total_time\n",
    "    coeff = (2 * TAU * np.exp(-(L + S)*TAU))/((1 - 2 * L * TAU)**2)\n",
    "    i_term = S_i - np.exp((L + S)*TAU) * P_i\n",
    "    j_term = S_j - np.exp((L + S)*TAU) * P_j\n",
    "    return coeff * i_term * j_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d3412fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "Processing detector 200/2304, total = 150.49356489781647\n",
      "Processing detector 400/2304, total = 150.49356489781647\n",
      "Processing detector 600/2304, total = 150.49356489781647\n",
      "Processing detector 800/2304, total = 150.49356489781647\n",
      "Processing detector 1000/2304, total = 150.49356489781647\n",
      "Processing detector 1200/2304, total = 150.49356489781647\n",
      "Processing detector 1400/2304, total = 150.49356489781647\n",
      "Processing detector 1600/2304, total = 150.49356489781647\n",
      "Processing detector 1800/2304, total = 150.49356489781647\n",
      "Processing detector 2000/2304, total = 150.49356489781647\n",
      "Processing detector 2200/2304, total = 150.49356489781647\n",
      "2.457448766556835\n"
     ]
    }
   ],
   "source": [
    "sp_estimate = 0\n",
    "detectors = singles['detector'].unique()\n",
    "for i in range(num_detectors):\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print(f\"Processing detector {i + 1}/{len(detectors)}, total = \" + str(total))\n",
    "    for j in range(i, num_detectors):\n",
    "        sp_estimate += randomsrate(i, j)\n",
    "\n",
    "print(sp_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8259ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_estimate = sp_estimate * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "46b0b41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.4469259934101\n"
     ]
    }
   ],
   "source": [
    "print(sp_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd3af3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = coincidences[coincidences['true'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8ea7cacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a107c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "dw_estimate = 0\n",
    "for t in singles['time']:\n",
    "    dw_estimate += np.searchsorted(singles['time'], t + DELAY + TAU) - np.searchsorted(singles['time'], t + TAU)\n",
    "print(dw_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8b30c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing detector 200/2304, total = 0.4858576652999432\n",
      "Processing detector 400/2304, total = 0.9384399817929115\n",
      "Processing detector 600/2304, total = 1.3583664178806412\n",
      "Processing detector 800/2304, total = 1.733067151955013\n",
      "Processing detector 1000/2304, total = 2.0639006815556997\n",
      "Processing detector 1200/2304, total = 2.346096633095667\n",
      "Processing detector 1400/2304, total = 2.581322612982198\n",
      "Processing detector 1600/2304, total = 2.7671906837088227\n",
      "Processing detector 1800/2304, total = 2.9058936105887465\n",
      "Processing detector 2000/2304, total = 2.996275632968659\n",
      "Processing detector 2200/2304, total = 3.040703559228618\n"
     ]
    }
   ],
   "source": [
    "sr_estimate = 0\n",
    "for i in range(num_detectors):\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print(f\"Processing detector {i + 1}/{len(detectors)}, total = \" + str(sr_estimate))\n",
    "    for j in range(i, num_detectors):\n",
    "        sr_estimate += 2 * TAU * singles_counts.get(i, 0) / total_time * singles_counts.get(j, 0) / total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6ebdb762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.79833424051856\n"
     ]
    }
   ],
   "source": [
    "print(sr_estimate * total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73226e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
